{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('Anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "2bf8f98cd9347e095df38b8480e7bc42e5fce1dfec3ce86d8029489262e0911d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "import AutogluonModels\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loaded model\n",
    "target_zone='zone_18'\n",
    "runtime = 600\n",
    "predictor = pickle.load(open(f'Frameworks/AutoGluon/{target_zone}/{target_zone}_{runtime}g', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the missing Data between training and testing dataset\n",
    "data_comlete = pd.read_csv(f'Dataset/{target_zone}.csv')\n",
    "#gap is the missing values\n",
    "gap = data_comlete.set_index('datetime')['2008-06-30 05:00:00': '2008-06-30 23:00:00']\n",
    "gap_target = gap['target']\n",
    "gap = gap.drop(columns=['target'])\n",
    "pred = gap[target_zone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "199695.1875\n"
     ]
    }
   ],
   "source": [
    "#run loop to calculate the prediction weeks\n",
    "for x in range(0, len(gap)-1):\n",
    "    #row is the current hour in the loop starting with 2008-07-01 00:00:00\n",
    "    row = gap[x:x+1]\n",
    "    #predict the value of hour X\n",
    "    pred[x]=predictor.predict(row, as_pandas=True)\n",
    "    #replace the value of target_zone at hour X+1 in the feature dataset\n",
    "    gap[target_zone][x+1]=pred[x]\n",
    "\n",
    "last_value=pred[18]\n",
    "print(last_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'Dataset/Zones/{target_zone}test.csv')\n",
    "#remove target from feature list\n",
    "features = test.drop('target', axis=1)\n",
    "#add the last prediction from the missing 19 value as the first target_column value\n",
    "features[target_zone][0]=last_value\n",
    "target = test['target']\n",
    "pred = test[target_zone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run loop to calculate the prediction weeks\n",
    "for x in range(0, len(target)):\n",
    "    #row is the current hour in the loop starting with 2008-07-01 00:00:00\n",
    "    row = features[x:x+1]\n",
    "    #predict the value of hour X\n",
    "    pred[x]=predictor.predict(row, as_pandas=True)\n",
    "    #replace the value of 'zone_4' at hour X+1 in the feature dataset\n",
    "    features[target_zone][x+1]=pred[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0      199695.187500\n1      176174.875000\n2      162132.125000\n3      152543.921875\n4      151543.671875\n           ...      \n162    311233.406250\n163    300444.718750\n164    287267.500000\n165    274760.468750\n166    239902.281250\nName: zone_18, Length: 167, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(features[target_zone])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0      176174.875000\n1      162132.125000\n2      152543.921875\n3      151543.671875\n4      165450.890625\n           ...      \n162    300444.718750\n163    287267.500000\n164    274760.468750\n165    239902.281250\n166    204273.468750\nName: zone_18, Length: 167, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics for AutoGloun zone_18_600\nMin Load: 129107.0\nMax Load: 352808.0\nAverage Load: 225798.89221556886\nR2: 0.9568953614073381\nMAE: 10878.899279565869\nMAPE: 0.050012556105317074\nMax Error: 35966.90625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import max_error\n",
    "\n",
    "print(f'Metrics for AutoGloun {target_zone}_{runtime}')\n",
    "print('Min Load:', target.min())\n",
    "print('Max Load:', target.max())\n",
    "print('Average Load:', target.mean())\n",
    "print('R2:', r2_score(target, pred))\n",
    "print('MAE:', mean_absolute_error(target, pred))\n",
    "print('MAPE:', mean_absolute_percentage_error(target, pred))\n",
    "print('Max Error:', max_error(target, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}